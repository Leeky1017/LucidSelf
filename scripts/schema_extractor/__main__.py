"""
Schema Extractor CLI - å‘½ä»¤è¡Œå…¥å£

ä½¿ç”¨æ–¹å¼:
    python -m schema_extractor extract <markdown_path> [--output <output_dir>]
    python -m schema_extractor batch <directory> [--output <output_dir>] [--exclude <book1,book2>]
    python -m schema_extractor validate <yaml_directory>
"""

import argparse
import sys
from pathlib import Path
from typing import List, Optional

from .extractors import extract_from_directory, extract_from_file
from .models import ExtractionResult
from .output import ReportGenerator, YAMLOutput


def cmd_extract(args):
    """æå–å•ä¸ªæ–‡ä»¶"""
    file_path = Path(args.file)
    if not file_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        sys.exit(1)
    
    output_dir = Path(args.output) if args.output else Path("data/semantics")
    
    print(f"ğŸ“„ æå–æ–‡ä»¶: {file_path}")
    result = extract_from_file(file_path, book_id=args.book_id)
    
    if result.errors:
        print(f"âš ï¸  å‘ç° {len(result.errors)} ä¸ªé”™è¯¯")
        for error in result.errors[:5]:
            print(f"   - {error}")
    
    # è¾“å‡ºåˆ°YAML
    output = YAMLOutput(output_dir)
    written = output.write_result(result)
    
    print(f"âœ… æå–å®Œæˆ:")
    print(f"   - å› å­: {len(result.factors)}")
    print(f"   - å™äº‹ç´ æ: {len(result.snippets)}")
    print(f"   - æœ¯è¯­: {len(result.terms)}")
    print(f"   - å…³ç³»: {len(result.relations)}")
    print(f"   - è¯æ®é“¾: {len(result.evidence_chains)}")
    print(f"   - è·¨ä½“ç³»æ˜ å°„: {len(result.cross_mappings)}")
    
    for category, path in written.items():
        print(f"   ğŸ“ {category}: {path}")


def cmd_batch(args):
    """æ‰¹é‡æå–ç›®å½•"""
    directory = Path(args.directory)
    if not directory.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {directory}")
        sys.exit(1)
    
    output_dir = Path(args.output) if args.output else Path("data/semantics")
    
    # è§£ææ’é™¤åˆ—è¡¨
    exclude_books: List[str] = []
    if args.exclude:
        exclude_books = [b.strip() for b in args.exclude.split(",")]
    
    # é»˜è®¤æ’é™¤çš„ä¹¦ç±ï¼ˆåªæ’é™¤æ•°æ®ä¸å®Œæ•´çš„ï¼‰
    default_excludes = [
        "è®°çº‚æ¸Šæµ·",  # å†…å®¹ä¸å®Œæ•´
        "collected works",  # åˆé›†ï¼Œä¸å•ç‹¬å¤„ç†
        "the collected works",
        # æ’é™¤æ¨¡æ¿å’Œè¯´æ˜æ–‡ä»¶
        "ç²¾æ ¡æ¨¡æ¿",
        "template",
        "readme",
        "å®¡è®¡æŠ¥å‘Š",
        "schemaå·¥ç¨‹è¯´æ˜",
        "å…¸ç±ç²¾æ ¡ä¸ç»“æ„åŒ–",
        "å…¸ç±ç»“æ„åŒ–ä½œä¸šæ‰‹å†Œ",
        "å› å­æœ¬ä½“",
        "ç»“æ„åŒ–æå–",
    ]
    exclude_books.extend(default_excludes)
    
    print(f"ğŸ“‚ æ‰¹é‡æå–ç›®å½•: {directory}")
    print(f"ğŸš« æ’é™¤ä¹¦ç±: {', '.join(exclude_books)}")
    
    results = extract_from_directory(directory, exclude_books=exclude_books)
    
    if not results:
        print("âš ï¸  æœªæ‰¾åˆ°å¯æå–çš„æ–‡ä»¶")
        sys.exit(0)
    
    # åˆå¹¶åŒä¸€book_idçš„æ‰€æœ‰ç»“æœï¼Œç„¶åè¾“å‡ºYAML
    output = YAMLOutput(output_dir)
    total_written = 0
    
    for book_id, book_results in results.items():
        # åˆå¹¶åŒä¸€å…¸ç±çš„æ‰€æœ‰æ–‡ä»¶ç»“æœ
        merged = ExtractionResult(
            source_file=", ".join(r.source_file for r in book_results),
            book_id=book_id,
        )
        
        # ä½¿ç”¨setå»é‡ï¼ˆä»…å¯¹å”¯ä¸€æ ‡è¯†å»é‡ï¼Œä¿ç•™åŒIDä¸åŒæ ‡ç­¾çš„å› å­ï¼‰
        seen_factor_keys = set()  # (factor_id, factor_label) ç»„åˆ
        seen_snippet_ids = set()
        seen_term_keys = set()
        seen_relation_ids = set()
        seen_evidence_ids = set()
        seen_concept_ids = set()
        
        for result in book_results:
            # åˆå¹¶å› å­ï¼ˆæŒ‰factor_id+factor_labelç»„åˆå»é‡ï¼Œä¿ç•™åŒIDä¸åŒæ ‡ç­¾ï¼‰
            for f in result.factors:
                key = (f.factor_id, f.factor_label)
                if key not in seen_factor_keys:
                    seen_factor_keys.add(key)
                    merged.factors.append(f)
            
            # åˆå¹¶å™äº‹ç´ æï¼ˆæŒ‰snippet_idå»é‡ï¼‰
            for s in result.snippets:
                if s.snippet_id not in seen_snippet_ids:
                    seen_snippet_ids.add(s.snippet_id)
                    merged.snippets.append(s)
            
            # åˆå¹¶æœ¯è¯­ï¼ˆæŒ‰ä¸­æ–‡æœ¯è¯­+è‹±æ–‡æœ¯è¯­ç»„åˆå»é‡ï¼‰
            for t in result.terms:
                key = (t.term_zh, t.term_en)
                if key not in seen_term_keys:
                    seen_term_keys.add(key)
                    merged.terms.append(t)
            
            # åˆå¹¶å…³ç³»ï¼ˆæŒ‰relation_idå»é‡ï¼‰
            for r in result.relations:
                if r.relation_id not in seen_relation_ids:
                    seen_relation_ids.add(r.relation_id)
                    merged.relations.append(r)
            
            # åˆå¹¶è¯æ®é“¾ï¼ˆæŒ‰evidence_idå»é‡ï¼‰
            for e in result.evidence_chains:
                if e.evidence_id not in seen_evidence_ids:
                    seen_evidence_ids.add(e.evidence_id)
                    merged.evidence_chains.append(e)
            
            # åˆå¹¶è·¨ä½“ç³»æ˜ å°„ï¼ˆæŒ‰concept_idå»é‡ï¼‰
            for c in result.cross_mappings:
                if c.concept_id not in seen_concept_ids:
                    seen_concept_ids.add(c.concept_id)
                    merged.cross_mappings.append(c)
            
            # åˆå¹¶é”™è¯¯å’Œè­¦å‘Š
            merged.errors.extend(result.errors)
            merged.warnings.extend(result.warnings)
        
        # å†™å…¥åˆå¹¶åçš„ç»“æœ
        written = output.write_result(merged)
        total_written += len(written)
    
    # ç”ŸæˆæŠ¥å‘Š
    report_gen = ReportGenerator(output_dir)
    report_path = report_gen.write_report(results)
    
    # ç»Ÿè®¡
    total_factors = sum(len(r.factors) for rs in results.values() for r in rs)
    total_snippets = sum(len(r.snippets) for rs in results.values() for r in rs)
    total_terms = sum(len(r.terms) for rs in results.values() for r in rs)
    total_relations = sum(len(r.relations) for rs in results.values() for r in rs)
    total_evidence = sum(len(r.evidence_chains) for rs in results.values() for r in rs)
    total_cross = sum(len(r.cross_mappings) for rs in results.values() for r in rs)
    total_errors = sum(len(r.errors) for rs in results.values() for r in rs)
    
    print(f"\nâœ… æ‰¹é‡æå–å®Œæˆ!")
    print(f"   ğŸ“š å…¸ç±æ•°: {len(results)}")
    print(f"   ğŸ“„ æ–‡ä»¶æ•°: {sum(len(rs) for rs in results.values())}")
    print(f"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"   ğŸ”¹ å› å­: {total_factors}")
    print(f"   ğŸ”¹ å™äº‹ç´ æ: {total_snippets}")
    print(f"   ğŸ”¹ æœ¯è¯­: {total_terms}")
    print(f"   ğŸ”¹ å…³ç³»: {total_relations}")
    print(f"   ğŸ”¹ è¯æ®é“¾: {total_evidence}")
    print(f"   ğŸ”¹ è·¨ä½“ç³»æ˜ å°„: {total_cross}")
    print(f"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    if total_errors > 0:
        print(f"   âš ï¸  é”™è¯¯: {total_errors}")
    print(f"   ğŸ“ æŠ¥å‘Š: {report_path}")


def cmd_validate(args):
    """éªŒè¯YAMLæ–‡ä»¶"""
    yaml_dir = Path(args.yaml_dir)
    if not yaml_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {yaml_dir}")
        sys.exit(1)
    
    import yaml as yaml_lib
    from .models import (
        ConfigFactor,
        ConfigRelation,
        CrossSystemMapping,
        EvidenceChainEntry,
        NarrativeSnippet,
        TermGlossary,
    )
    
    errors = []
    validated = 0
    
    # éªŒè¯å„ç±»YAMLæ–‡ä»¶
    for yaml_file in yaml_dir.rglob("*.yaml"):
        try:
            with open(yaml_file, 'r', encoding='utf-8') as f:
                data = yaml_lib.safe_load(f)
            
            # æ ¹æ®æ–‡ä»¶è·¯å¾„ç¡®å®šç±»å‹å¹¶éªŒè¯
            if "factors" in str(yaml_file):
                for item in data.get("factors", []):
                    ConfigFactor(**item)
                    validated += 1
            elif "snippets" in str(yaml_file):
                for item in data.get("snippets", []):
                    NarrativeSnippet(**item)
                    validated += 1
            elif "terms" in str(yaml_file):
                for item in data.get("terms", []):
                    TermGlossary(**item)
                    validated += 1
            elif "relations" in str(yaml_file):
                for item in data.get("relations", []):
                    ConfigRelation(**item)
                    validated += 1
            elif "evidence" in str(yaml_file):
                for item in data.get("evidence_chains", []):
                    EvidenceChainEntry(**item)
                    validated += 1
            elif "cross_system" in str(yaml_file):
                for item in data.get("cross_mappings", []):
                    CrossSystemMapping(**item)
                    validated += 1
                    
        except Exception as e:
            errors.append(f"{yaml_file}: {str(e)}")
    
    if errors:
        print(f"âŒ éªŒè¯å¤±è´¥! å‘ç° {len(errors)} ä¸ªé”™è¯¯:")
        for error in errors[:20]:
            print(f"   - {error}")
        if len(errors) > 20:
            print(f"   ... è¿˜æœ‰ {len(errors) - 20} ä¸ªé”™è¯¯")
        sys.exit(1)
    else:
        print(f"âœ… éªŒè¯é€šè¿‡! å…±éªŒè¯ {validated} æ¡è®°å½•")


def main():
    parser = argparse.ArgumentParser(
        description="Schema Extractor - ä»ç²¾æ ¡Markdownæå–ç»“æ„åŒ–æ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python -m schema_extractor extract å…¸ç±/ä¸­æ–‡å…¸ç±/æ»´å¤©é«“/ç¼–è¾‘/æ»´å¤©é«“_å®Œæ•´è§„èŒƒåŒ–_ä¸Šå·.md
  python -m schema_extractor batch å…¸ç±/ä¸­æ–‡å…¸ç± --output data/semantics
  python -m schema_extractor batch å…¸ç±/ --exclude "æ¢¦æ—ç„è§£,è®°çº‚æ¸Šæµ·"
  python -m schema_extractor validate data/semantics
        """
    )
    
    subparsers = parser.add_subparsers(dest="command", help="å­å‘½ä»¤")
    
    # extract å‘½ä»¤
    extract_parser = subparsers.add_parser("extract", help="æå–å•ä¸ªæ–‡ä»¶")
    extract_parser.add_argument("file", help="Markdownæ–‡ä»¶è·¯å¾„")
    extract_parser.add_argument("--output", "-o", help="è¾“å‡ºç›®å½•", default="data/schema_staging")
    extract_parser.add_argument("--book-id", help="æŒ‡å®šbook_idï¼ˆé»˜è®¤ä»è·¯å¾„æ¨æ–­ï¼‰")
    extract_parser.set_defaults(func=cmd_extract)
    
    # batch å‘½ä»¤
    batch_parser = subparsers.add_parser("batch", help="æ‰¹é‡æå–ç›®å½•")
    batch_parser.add_argument("directory", help="ç›®å½•è·¯å¾„")
    batch_parser.add_argument("--output", "-o", help="è¾“å‡ºç›®å½•", default="data/schema_staging")
    batch_parser.add_argument("--exclude", "-e", help="æ’é™¤çš„ä¹¦ç±ï¼Œé€—å·åˆ†éš”")
    batch_parser.set_defaults(func=cmd_batch)
    
    # validate å‘½ä»¤
    validate_parser = subparsers.add_parser("validate", help="éªŒè¯YAMLæ–‡ä»¶")
    validate_parser.add_argument("yaml_dir", help="YAMLç›®å½•è·¯å¾„")
    validate_parser.set_defaults(func=cmd_validate)
    
    args = parser.parse_args()
    
    if args.command is None:
        parser.print_help()
        sys.exit(0)
    
    args.func(args)


if __name__ == "__main__":
    main()
