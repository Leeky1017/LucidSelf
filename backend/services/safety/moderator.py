"""
Safety Moderator

å†…å®¹å®‰å…¨å®¡æ ¸å™¨ã€‚

å¯¹ç…§ tasks.md 7.1-7.2:
- Requirements: 5.1.1-5.1.3
- âš ï¸ é™·é˜±: ä¸è¦è¿‡åº¦è¿‡æ»¤å¯¼è‡´æ­£å¸¸å†…å®¹è¢«æ‹¦æˆª

è®¾è®¡åŸåˆ™:
- ç™½åå•æ¨¡å¼: ä¼˜å…ˆå…è®¸ï¼Œåªæ‹¦æˆªæ˜ç¡®æœ‰å®³å†…å®¹
- æ•æ„Ÿè¯é¢˜æ ‡è®°: ä¸æ‹¦æˆªä½†æ·»åŠ æç¤º
- åˆ†çº§å¤„ç†: ä¸åŒçº§åˆ«ä¸åŒå¤„ç†æ–¹å¼
"""

import logging
import re
from dataclasses import dataclass, field
from enum import Enum
from typing import List, Optional, Set

logger = logging.getLogger(__name__)


class SafetyLevel(str, Enum):
    """å®‰å…¨çº§åˆ«"""
    SAFE = "safe"              # å®Œå…¨å®‰å…¨
    CAUTION = "caution"        # éœ€è¦æ³¨æ„ï¼Œæ·»åŠ æç¤º
    SENSITIVE = "sensitive"    # æ•æ„Ÿè¯é¢˜ï¼Œéœ€è¦ disclaimer
    BLOCKED = "blocked"        # è¢«æ‹¦æˆª


class SensitiveTopic(str, Enum):
    """æ•æ„Ÿè¯é¢˜ç±»å‹"""
    HEALTH = "health"          # å¥åº·/åŒ»ç–—
    LEGAL = "legal"            # æ³•å¾‹
    FINANCIAL = "financial"    # è´¢åŠ¡/æŠ•èµ„
    MENTAL_HEALTH = "mental_health"  # å¿ƒç†å¥åº·
    CRISIS = "crisis"          # å±æœº (è‡ªä¼¤/è‡ªæ€)


@dataclass
class SafetyResult:
    """å®‰å…¨æ£€æŸ¥ç»“æœ"""
    level: SafetyLevel
    passed: bool
    topics: List[SensitiveTopic] = field(default_factory=list)
    warnings: List[str] = field(default_factory=list)
    filtered_content: Optional[str] = None
    disclaimer: Optional[str] = None


class SafetyModerator:
    """
    å®‰å…¨å®¡æ ¸å™¨
    
    åŠŸèƒ½:
    - è¾“å…¥å†…å®¹æ£€æŸ¥
    - è¾“å‡ºå†…å®¹æ£€æŸ¥
    - æ•æ„Ÿè¯é¢˜æ£€æµ‹
    - Disclaimer æ³¨å…¥
    
    âš ï¸ é‡è¦:
    - ä½¿ç”¨ç™½åå•æ¨¡å¼ï¼Œé¿å…è¿‡åº¦è¿‡æ»¤
    - æ•æ„Ÿè¯é¢˜ä¸ç›´æ¥æ‹¦æˆªï¼Œè€Œæ˜¯æ·»åŠ  disclaimer
    - åªæœ‰æ˜ç¡®æœ‰å®³å†…å®¹æ‰è¢«æ‹¦æˆª
    """
    
    # æ•æ„Ÿè¯é¢˜å…³é”®è¯ (ç”¨äºæ ‡è®°ï¼Œä¸æ‹¦æˆª)
    SENSITIVE_KEYWORDS = {
        SensitiveTopic.HEALTH: {
            "zh": ["ç–¾ç—…", "æ²»ç–—", "è¯ç‰©", "åŒ»é™¢", "è¯Šæ–­", "ç—‡çŠ¶", "æ‰‹æœ¯"],
            "en": ["disease", "treatment", "medicine", "hospital", "diagnosis", "symptoms", "surgery"],
        },
        SensitiveTopic.LEGAL: {
            "zh": ["æ³•å¾‹", "è¯‰è®¼", "åˆåŒ", "å¾‹å¸ˆ", "åˆ¤å†³", "èµ·è¯‰"],
            "en": ["legal", "lawsuit", "contract", "lawyer", "verdict", "sue"],
        },
        SensitiveTopic.FINANCIAL: {
            "zh": ["æŠ•èµ„", "è‚¡ç¥¨", "åŸºé‡‘", "ç†è´¢", "è´·æ¬¾", "ä¿¡ç”¨å¡"],
            "en": ["invest", "stock", "fund", "finance", "loan", "credit"],
        },
        SensitiveTopic.MENTAL_HEALTH: {
            "zh": ["æŠ‘éƒ", "ç„¦è™‘", "å‹åŠ›", "æƒ…ç»ªä½è½", "å¤±çœ "],
            "en": ["depression", "anxiety", "stress", "emotional", "insomnia"],
        },
    }
    
    # å±æœºå…³é”®è¯ (éœ€è¦ç‰¹æ®Šå¤„ç†)
    CRISIS_KEYWORDS = {
        "zh": ["è‡ªæ€", "è‡ªæ®‹", "ä¸æƒ³æ´»", "ç»“æŸç”Ÿå‘½", "è½»ç”Ÿ", "è‡ªå°½"],
        "en": ["suicide", "self-harm", "end my life", "kill myself", "don't want to live"],
    }
    
    # æ˜ç¡®æœ‰å®³å†…å®¹ (ç›´æ¥æ‹¦æˆª)
    BLOCKED_PATTERNS = [
        # ä»…æ‹¦æˆªæ˜ç¡®æœ‰å®³çš„å†…å®¹
        r"(?i)(how\s+to\s+make\s+a\s+bomb)",
        r"(?i)(instructions\s+for\s+illegal)",
    ]
    
    # Disclaimer æ¨¡æ¿
    DISCLAIMERS = {
        SensitiveTopic.HEALTH: {
            "zh": "âš•ï¸ æ¸©é¦¨æç¤ºï¼šä»¥ä¸Šå†…å®¹ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆåŒ»ç–—å»ºè®®ã€‚å¦‚æœ‰å¥åº·é—®é¢˜ï¼Œè¯·å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿã€‚",
            "en": "âš•ï¸ Disclaimer: This content is for reference only and does not constitute medical advice. Please consult a healthcare professional for health concerns.",
        },
        SensitiveTopic.LEGAL: {
            "zh": "âš–ï¸ æ¸©é¦¨æç¤ºï¼šä»¥ä¸Šå†…å®¹ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæ³•å¾‹å»ºè®®ã€‚å¦‚æœ‰æ³•å¾‹é—®é¢˜ï¼Œè¯·å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆã€‚",
            "en": "âš–ï¸ Disclaimer: This content is for reference only and does not constitute legal advice. Please consult a qualified lawyer for legal matters.",
        },
        SensitiveTopic.FINANCIAL: {
            "zh": "ğŸ’° æ¸©é¦¨æç¤ºï¼šä»¥ä¸Šå†…å®¹ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œè¯·è°¨æ…å†³ç­–ã€‚",
            "en": "ğŸ’° Disclaimer: This content is for reference only and does not constitute investment advice. Investments carry risks, please make decisions carefully.",
        },
        SensitiveTopic.MENTAL_HEALTH: {
            "zh": "ğŸ§  æ¸©é¦¨æç¤ºï¼šå¦‚æœæ‚¨æ­£åœ¨ç»å†å›°éš¾ï¼Œè¯·è®°ä½æ‚¨å¹¶ä¸å­¤å•ã€‚å¦‚éœ€å¸®åŠ©ï¼Œè¯·è”ç³»ä¸“ä¸šå¿ƒç†å’¨è¯¢å¸ˆã€‚",
            "en": "ğŸ§  Reminder: If you are going through a difficult time, remember you are not alone. Please reach out to a mental health professional if needed.",
        },
    }
    
    def __init__(self, language: str = "zh"):
        """
        åˆå§‹åŒ–å®¡æ ¸å™¨
        
        Args:
            language: è¯­è¨€ ("zh" æˆ– "en")
        """
        self.language = language
        self._blocked_patterns = [re.compile(p) for p in self.BLOCKED_PATTERNS]
    
    def check_input(self, text: str) -> SafetyResult:
        """
        æ£€æŸ¥è¾“å…¥å†…å®¹
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            SafetyResult
        """
        if not text:
            return SafetyResult(level=SafetyLevel.SAFE, passed=True)
        
        # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®æœ‰å®³å†…å®¹
        for pattern in self._blocked_patterns:
            if pattern.search(text):
                logger.warning("Blocked harmful input content")
                return SafetyResult(
                    level=SafetyLevel.BLOCKED,
                    passed=False,
                    warnings=["Input contains harmful content"],
                )
        
        # 2. æ£€æŸ¥å±æœºå…³é”®è¯
        crisis_keywords = self.CRISIS_KEYWORDS.get(self.language, [])
        for keyword in crisis_keywords:
            if keyword in text.lower():
                return SafetyResult(
                    level=SafetyLevel.SENSITIVE,
                    passed=True,  # ä¸æ‹¦æˆªï¼Œä½†æ ‡è®°
                    topics=[SensitiveTopic.CRISIS],
                    warnings=["Crisis-related content detected"],
                )
        
        # 3. æ£€æŸ¥æ•æ„Ÿè¯é¢˜
        detected_topics = self._detect_topics(text)
        
        if detected_topics:
            return SafetyResult(
                level=SafetyLevel.CAUTION,
                passed=True,
                topics=detected_topics,
            )
        
        return SafetyResult(level=SafetyLevel.SAFE, passed=True)
    
    def check_output(self, text: str) -> SafetyResult:
        """
        æ£€æŸ¥è¾“å‡ºå†…å®¹
        
        Args:
            text: è¾“å‡ºæ–‡æœ¬
            
        Returns:
            SafetyResult (åŒ…å«å¯èƒ½çš„ disclaimer)
        """
        if not text:
            return SafetyResult(level=SafetyLevel.SAFE, passed=True)
        
        # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®æœ‰å®³å†…å®¹
        for pattern in self._blocked_patterns:
            if pattern.search(text):
                logger.warning("Blocked harmful output content")
                return SafetyResult(
                    level=SafetyLevel.BLOCKED,
                    passed=False,
                    warnings=["Output contains harmful content"],
                    filtered_content="[å†…å®¹å·²è¿‡æ»¤]" if self.language == "zh" else "[Content filtered]",
                )
        
        # 2. æ£€æŸ¥æ•æ„Ÿè¯é¢˜å¹¶æ·»åŠ  disclaimer
        detected_topics = self._detect_topics(text)
        
        if detected_topics:
            disclaimers = []
            for topic in detected_topics:
                if topic in self.DISCLAIMERS:
                    disclaimer = self.DISCLAIMERS[topic].get(self.language, "")
                    if disclaimer:
                        disclaimers.append(disclaimer)
            
            combined_disclaimer = "\n".join(disclaimers) if disclaimers else None
            
            return SafetyResult(
                level=SafetyLevel.CAUTION,
                passed=True,
                topics=detected_topics,
                disclaimer=combined_disclaimer,
            )
        
        return SafetyResult(level=SafetyLevel.SAFE, passed=True)
    
    def _detect_topics(self, text: str) -> List[SensitiveTopic]:
        """æ£€æµ‹æ•æ„Ÿè¯é¢˜"""
        detected = []
        text_lower = text.lower()
        
        for topic, keywords_dict in self.SENSITIVE_KEYWORDS.items():
            keywords = keywords_dict.get(self.language, [])
            for keyword in keywords:
                if keyword in text_lower:
                    if topic not in detected:
                        detected.append(topic)
                    break
        
        return detected
    
    def inject_disclaimer(self, text: str, topics: List[SensitiveTopic]) -> str:
        """
        æ³¨å…¥ disclaimer
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            topics: æ•æ„Ÿè¯é¢˜åˆ—è¡¨
            
        Returns:
            å¸¦ disclaimer çš„æ–‡æœ¬
        """
        if not topics:
            return text
        
        disclaimers = []
        for topic in topics:
            if topic in self.DISCLAIMERS:
                disclaimer = self.DISCLAIMERS[topic].get(self.language, "")
                if disclaimer and disclaimer not in disclaimers:
                    disclaimers.append(disclaimer)
        
        if disclaimers:
            separator = "\n\n---\n\n"
            return text + separator + "\n".join(disclaimers)
        
        return text
