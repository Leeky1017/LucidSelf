# .github/workflows/calculator-tests.yml
# CI/CD workflow for Calculator accuracy audit tests
#
# This workflow runs:
# 1. Golden Set tests - verified test cases against authoritative data
# 2. Property-based tests - Hypothesis-based correctness property validation
# 3. Coverage matrix checks - ensures test coverage meets requirements
#
# Requirements: 10.7

name: Calculator Accuracy Tests

on:
  push:
    branches: [main, develop]
    paths:
      - 'backend/calculators/**'
      - 'backend/core/testing/**'
      - 'data/solar_terms/**'
      - 'data/golden_set/**'
      - '.github/workflows/calculator-tests.yml'
  pull_request:
    branches: [main, develop]
    paths:
      - 'backend/calculators/**'
      - 'backend/core/testing/**'
      - 'data/solar_terms/**'
      - 'data/golden_set/**'
      - '.github/workflows/calculator-tests.yml'
  workflow_dispatch:
    inputs:
      calculator:
        description: 'Specific calculator to test (bazi/ziwei/yijing/astro/tarot/dream/all)'
        required: false
        default: 'all'
      run_slow_tests:
        description: 'Run slow/comprehensive tests'
        required: false
        default: 'false'
        type: boolean

env:
  PYTHON_VERSION: '3.12'
  HYPOTHESIS_SEED: ${{ github.run_id }}

jobs:
  # ==========================================================================
  # Golden Set Tests - Verified test cases against authoritative data
  # ==========================================================================
  golden-set-tests:
    name: Golden Set Tests
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        calculator: [bazi, ziwei, yijing, astro, tarot, dream]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov hypothesis pydantic python-dateutil
          pip install -e . 2>/dev/null || true
          # Install any additional calculator-specific dependencies
          if [ -f "backend/calculators/${{ matrix.calculator }}/requirements.txt" ]; then
            pip install -r "backend/calculators/${{ matrix.calculator }}/requirements.txt"
          fi
      
      - name: Check Golden Set exists
        id: check_golden
        run: |
          GOLDEN_PATH="backend/calculators/${{ matrix.calculator }}/tests/golden_cases"
          if [ -d "$GOLDEN_PATH" ] && [ "$(ls -A $GOLDEN_PATH/*.jsonl 2>/dev/null)" ]; then
            echo "has_golden=true" >> $GITHUB_OUTPUT
            echo "Golden Set found for ${{ matrix.calculator }}"
          else
            echo "has_golden=false" >> $GITHUB_OUTPUT
            echo "No Golden Set found for ${{ matrix.calculator }}"
          fi
      
      - name: Run Golden Set tests
        if: steps.check_golden.outputs.has_golden == 'true'
        run: |
          pytest backend/calculators/${{ matrix.calculator }}/tests/ \
            -v \
            --tb=short \
            -k "golden or Golden" \
            --junitxml=golden-set-results-${{ matrix.calculator }}.xml
        env:
          PYTHONPATH: ${{ github.workspace }}
      
      - name: Upload Golden Set results
        if: always() && steps.check_golden.outputs.has_golden == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: golden-set-results-${{ matrix.calculator }}
          path: golden-set-results-${{ matrix.calculator }}.xml
          retention-days: 30

  # ==========================================================================
  # Property-Based Tests - Hypothesis-based correctness validation
  # ==========================================================================
  property-tests:
    name: Property Tests
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        calculator: [bazi, ziwei, yijing, astro, tarot, dream]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov hypothesis pydantic python-dateutil
          pip install -e . 2>/dev/null || true
      
      - name: Run property-based tests
        run: |
          pytest backend/calculators/${{ matrix.calculator }}/tests/ \
            -v \
            --tb=short \
            -k "property or Property" \
            --hypothesis-seed=${{ env.HYPOTHESIS_SEED }} \
            --junitxml=property-test-results-${{ matrix.calculator }}.xml
        env:
          PYTHONPATH: ${{ github.workspace }}
      
      - name: Upload property test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: property-test-results-${{ matrix.calculator }}
          path: property-test-results-${{ matrix.calculator }}.xml
          retention-days: 30

  # ==========================================================================
  # Core Testing Infrastructure Tests
  # ==========================================================================
  core-tests:
    name: Core Testing Infrastructure
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov hypothesis pydantic python-dateutil
          pip install -e . 2>/dev/null || true
      
      - name: Run core testing infrastructure tests
        run: |
          pytest backend/core/testing/tests/ \
            -v \
            --tb=short \
            --cov=backend/core/testing \
            --cov-report=xml \
            --junitxml=core-test-results.xml
        env:
          PYTHONPATH: ${{ github.workspace }}
      
      - name: Upload core test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: core-test-results
          path: |
            core-test-results.xml
            coverage.xml
          retention-days: 30

  # ==========================================================================
  # Coverage Matrix Check - Validates test coverage meets requirements
  # ==========================================================================
  coverage-check:
    name: Coverage Matrix Check
    runs-on: ubuntu-latest
    needs: [golden-set-tests, property-tests]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pydantic python-dateutil
      
      - name: Run coverage matrix check
        run: |
          python scripts/check_golden_set_coverage.py --report
        env:
          PYTHONPATH: ${{ github.workspace }}
      
      - name: Upload coverage report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-matrix-report
          path: coverage_matrix_report.json
          retention-days: 30

  # ==========================================================================
  # Comprehensive Tests (slow) - Full audit across all years
  # ==========================================================================
  comprehensive-tests:
    name: Comprehensive Tests
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.run_slow_tests == 'true'
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pytest pytest-cov hypothesis pydantic python-dateutil
          pip install -e . 2>/dev/null || true
      
      - name: Run comprehensive tests
        run: |
          pytest backend/calculators/ \
            -v \
            --tb=short \
            -m "slow" \
            --junitxml=comprehensive-test-results.xml
        env:
          PYTHONPATH: ${{ github.workspace }}
      
      - name: Upload comprehensive test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-results
          path: comprehensive-test-results.xml
          retention-days: 30

  # ==========================================================================
  # Summary Job - Aggregates all test results
  # ==========================================================================
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [golden-set-tests, property-tests, core-tests, coverage-check]
    if: always()
    
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: test-results
      
      - name: Generate summary
        run: |
          echo "## Calculator Accuracy Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Type | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| Golden Set Tests | ${{ needs.golden-set-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Property Tests | ${{ needs.property-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Core Tests | ${{ needs.core-tests.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Coverage Check | ${{ needs.coverage-check.result }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "Test results and coverage reports are available as workflow artifacts." >> $GITHUB_STEP_SUMMARY
      
      - name: Check overall status
        if: needs.golden-set-tests.result == 'failure' || needs.property-tests.result == 'failure' || needs.core-tests.result == 'failure'
        run: |
          echo "One or more test jobs failed!"
          exit 1
